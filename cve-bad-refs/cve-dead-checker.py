import csv
import re

# Read the list of dead domains
dead_domains = []
with open('dead-dns.txt', 'r') as dead_file:
    for line in dead_file:
        dead_domains.append(line.strip())

# Create a set to store the dead domains for faster lookup
dead_domains_set = set(dead_domains)

# Create a list to store CVEs with references to dead domains
cves_with_dead_domains = []

# Read the allitems.csv file and check for references to dead domains
with open('allitems.csv', 'r') as csv_file:
    reader = csv.reader(csv_file)
    for row in reader:
        if len(row) >= 4:
            cve_id = row[0]
            references = row[3]
            # Use regular expressions to extract all domains in the references column
            referenced_domains = re.findall(r'tps?://([^/]+)', references)
            # Check if any of the referenced domains are in the set of dead domains
            for domain in referenced_domains:
                if domain in dead_domains_set:
                    cves_with_dead_domains.append((cve_id, domain))

# Write the result to a new CSV file
with open('cves_with_dead_domains.csv', 'w', newline='') as output_file:
    writer = csv.writer(output_file)
    writer.writerow(['CVE', 'Dead Domain'])
    writer.writerows(cves_with_dead_domains)
